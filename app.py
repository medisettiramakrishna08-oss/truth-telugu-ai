import streamlit as st
from huggingface_hub import InferenceClient
from PIL import Image

# --- ‡∞™‡±á‡∞ú‡±Ä ‡∞°‡∞ø‡∞ú‡±à‡∞®‡±ç ---
st.set_page_config(page_title="Truth Telugu AI Director", page_icon="üé¨", layout="centered")
st.title("üé¨ Image to Video Prompt (Official)")
st.write("Stable Version using Hugging Face Official Client.")

# --- ‡∞∏‡±à‡∞°‡±ç‚Äå‡∞¨‡∞æ‡∞∞‡±ç ---
st.sidebar.header("üîë Setup")
api_key = st.sidebar.text_input("Hugging Face Access Token:", type="password")
st.sidebar.info("Settings -> Access Tokens ‡∞®‡±Å‡∞Ç‡∞°‡∞ø 'Write' ‡∞™‡∞∞‡±ç‡∞Æ‡∞ø‡∞∑‡∞®‡±ç ‡∞â‡∞®‡±ç‡∞® ‡∞ü‡±ã‡∞ï‡±Ü‡∞®‡±ç ‡∞µ‡∞æ‡∞°‡∞Ç‡∞°‡∞ø.")

if api_key:
    uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        # ‡∞á‡∞Æ‡±á‡∞ú‡±ç ‡∞ö‡±Ç‡∞™‡∞ø‡∞Ç‡∞ö‡±Å
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded Image", use_column_width=True)

        if st.button("Generate Prompt üöÄ"):
            with st.spinner("AI ‡∞Ü‡∞≤‡±ã‡∞ö‡∞ø‡∞∏‡±ç‡∞§‡±ã‡∞Ç‡∞¶‡∞ø... (Connecting via Official Client)"):
                try:
                    # ‡∞Ö‡∞´‡±Ä‡∞∑‡∞ø‡∞Ø‡∞≤‡±ç ‡∞ï‡±ç‡∞≤‡∞Ø‡∞ø‡∞Ç‡∞ü‡±ç ‡∞∏‡±Ü‡∞ü‡∞™‡±ç
                    client = InferenceClient(token=api_key)

                    # ‡∞Æ‡±ã‡∞°‡∞≤‡±ç: LLaVA (‡∞á‡∞Æ‡±á‡∞ú‡±ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡±á ‡∞¨‡±Ü‡∞∏‡±ç‡∞ü‡±ç ‡∞´‡±ç‡∞∞‡±Ä ‡∞Æ‡±ã‡∞°‡∞≤‡±ç)
                    # ‡∞á‡∞¶‡∞ø ‡∞á‡∞Æ‡±á‡∞ú‡±ç‚Äå‡∞®‡∞ø ‡∞ö‡±Ç‡∞∏‡∞ø ‡∞Æ‡∞®‡∞Ç ‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞® ‡∞¶‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø
                    model_id = "llava-hf/llava-1.5-7b-hf"

                    # AI ‡∞ï‡∞ø ‡∞™‡∞Ç‡∞™‡∞æ‡∞≤‡±ç‡∞∏‡∞ø‡∞® ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®
                    prompt = "USER: <image>\nDescribe this image in great detail for a cinematic video generation prompt. Mention the movement, camera angle, and lighting.\nASSISTANT:"
                    
                    # ‡∞á‡∞Æ‡±á‡∞ú‡±ç‚Äå‡∞®‡∞ø ‡∞ü‡±Ü‡∞ï‡±ç‡∞∏‡±ç‡∞ü‡±ç‚Äå‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡±á ‡∞™‡±ç‡∞∞‡∞æ‡∞∏‡±Ü‡∞∏‡±ç
                    # stream=False ‡∞Ö‡∞Ç‡∞ü‡±á ‡∞Æ‡±ä‡∞§‡±ç‡∞§‡∞Ç ‡∞Ü‡∞®‡±ç‡∞∏‡∞∞‡±ç ‡∞í‡∞ï‡±á‡∞∏‡∞æ‡∞∞‡∞ø ‡∞á‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø
                    response = client.text_generation(
                        prompt, 
                        model=model_id, 
                        max_new_tokens=250, 
                        stream=False,
                        # ‡∞á‡∞Æ‡±á‡∞ú‡±ç‚Äå‡∞®‡∞ø ‡∞°‡±à‡∞∞‡±Ü‡∞ï‡±ç‡∞ü‡±ç‚Äå‡∞ó‡∞æ ‡∞™‡∞Ç‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç (‡∞Æ‡±Å‡∞®‡±Å‡∞™‡∞ü‡∞ø‡∞≤‡∞æ base64 ‡∞Ö‡∞µ‡∞∏‡∞∞‡∞Ç ‡∞≤‡±á‡∞¶‡±Å)
                        images=[image] 
                    )

                    # ‡∞∞‡∞ø‡∞ú‡∞≤‡±ç‡∞ü‡±ç ‡∞ö‡±Ç‡∞™‡∞ø‡∞Ç‡∞ö‡±Å
                    # ‡∞ï‡±ä‡∞®‡±ç‡∞®‡∞ø‡∞∏‡∞æ‡∞∞‡±ç‡∞≤‡±Å ‡∞∞‡∞ø‡∞ú‡∞≤‡±ç‡∞ü‡±ç ‡∞≤‡±ã ‡∞Æ‡∞® ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞ï‡±Ç‡∞°‡∞æ ‡∞ï‡∞≤‡∞ø‡∞∏‡∞ø ‡∞µ‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø, ‡∞¶‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞ï‡±ç‡∞≤‡±Ä‡∞®‡±ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ç
                    final_answer = response.replace("USER: <image>", "").replace(prompt, "").strip()
                    
                    st.success("Success!")
                    st.subheader("üé• Video Prompt:")
                    st.write(final_answer)

                except Exception as e:
                    # ‡∞é‡∞∞‡±ç‡∞∞‡∞∞‡±ç ‡∞µ‡∞∏‡±ç‡∞§‡±á ‡∞ï‡±ç‡∞≤‡∞ø‡∞Ø‡∞∞‡±ç ‡∞ó‡∞æ ‡∞ö‡±Ç‡∞™‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞Ç‡∞¶‡∞ø
                    st.error(f"Error: {e}")
                    st.warning("‡∞í‡∞ï‡∞µ‡±á‡∞≥ 'Model is loading' ‡∞Ö‡∞®‡∞ø ‡∞µ‡∞∏‡±ç‡∞§‡±á, ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø 30 ‡∞∏‡±Ü‡∞ï‡∞®‡±ç‡∞≤‡±Å ‡∞Ü‡∞ó‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≥‡±Ä ‡∞¨‡∞ü‡∞®‡±ç ‡∞®‡±ä‡∞ï‡±ç‡∞ï‡∞Ç‡∞°‡∞ø.")
else:
    st.warning("üëà ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞é‡∞°‡∞Æ ‡∞µ‡±à‡∞™‡±Å‡∞® ‡∞Æ‡±Ä Hugging Face Token ‡∞é‡∞Ç‡∞ü‡∞∞‡±ç ‡∞ö‡±á‡∞Ø‡∞Ç‡∞°‡∞ø.")
